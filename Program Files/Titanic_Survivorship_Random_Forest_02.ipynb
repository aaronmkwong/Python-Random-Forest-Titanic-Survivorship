{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd # data frames\n",
    "import numpy as np # numerical calculations\n",
    "import matplotlib.pyplot as plt # to display results\n",
    "from sklearn.model_selection import train_test_split # to split data into train and test\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree modeling\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest modeling\n",
    "from sklearn.metrics import classification_report,confusion_matrix # model results\n",
    "from sklearn.inspection import permutation_importance # feature importance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Military</th>\n",
       "      <th>Nobility</th>\n",
       "      <th>Peerage</th>\n",
       "      <th>Religious</th>\n",
       "      <th>Untitled</th>\n",
       "      <th>Male</th>\n",
       "      <th>EmbrkQ</th>\n",
       "      <th>EmbrkS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  SibSp  Parch      Fare       Age  Military  \\\n",
       "0     0.000000       0.0     1.0  0.125    0.0  0.014151  0.271174       0.0   \n",
       "1     0.001124       1.0     0.0  0.125    0.0  0.139136  0.472229       0.0   \n",
       "2     0.002247       1.0     1.0  0.000    0.0  0.015469  0.321438       0.0   \n",
       "3     0.003371       1.0     0.0  0.125    0.0  0.103644  0.434531       0.0   \n",
       "4     0.004494       0.0     1.0  0.000    0.0  0.015713  0.434531       0.0   \n",
       "\n",
       "   Nobility  Peerage  Religious  Untitled  Male  EmbrkQ  EmbrkS  \n",
       "0       0.0      0.0        0.0       1.0   1.0     0.0     1.0  \n",
       "1       0.0      0.0        0.0       1.0   0.0     0.0     0.0  \n",
       "2       0.0      0.0        0.0       1.0   0.0     0.0     1.0  \n",
       "3       0.0      0.0        0.0       1.0   0.0     0.0     1.0  \n",
       "4       0.0      0.0        0.0       1.0   1.0     0.0     1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get engineered and scaled data from logistic regression project and display top 5 records \n",
    "\n",
    "modified_data_02_df = pd.read_csv('modified_data_02_df.csv') # read from user directory\n",
    "\n",
    "modified_data_02_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Military</th>\n",
       "      <th>Nobility</th>\n",
       "      <th>Peerage</th>\n",
       "      <th>Religious</th>\n",
       "      <th>Male</th>\n",
       "      <th>EmbrkQ</th>\n",
       "      <th>EmbrkS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  SibSp  Parch      Fare       Age  Military  \\\n",
       "0     0.000000       0.0     1.0  0.125    0.0  0.014151  0.271174       0.0   \n",
       "1     0.001124       1.0     0.0  0.125    0.0  0.139136  0.472229       0.0   \n",
       "2     0.002247       1.0     1.0  0.000    0.0  0.015469  0.321438       0.0   \n",
       "3     0.003371       1.0     0.0  0.125    0.0  0.103644  0.434531       0.0   \n",
       "4     0.004494       0.0     1.0  0.000    0.0  0.015713  0.434531       0.0   \n",
       "\n",
       "   Nobility  Peerage  Religious  Male  EmbrkQ  EmbrkS  \n",
       "0       0.0      0.0        0.0   1.0     0.0     1.0  \n",
       "1       0.0      0.0        0.0   0.0     0.0     0.0  \n",
       "2       0.0      0.0        0.0   0.0     0.0     1.0  \n",
       "3       0.0      0.0        0.0   0.0     0.0     1.0  \n",
       "4       0.0      0.0        0.0   1.0     0.0     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop features\n",
    "\n",
    "modified_data_03_df = modified_data_02_df.drop(['Untitled'], axis=1)\n",
    "modified_data_03_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assess model performance\n",
    "\n",
    "def rf_mod_assess(dataframe, target, trials, rf_est):\n",
    "    \n",
    "    rf_models_list = []\n",
    "    \n",
    "    # ith trial used as random state \n",
    "    for i in range(1,trials+1): \n",
    "        \n",
    "        # split into train and test datasets\n",
    "        x_train, x_test, y_train, y_test = train_test_split(dataframe.drop(target,axis=1), \n",
    "                                                            dataframe[target], test_size=0.30, \n",
    "                                                            random_state=i)\n",
    "        # make predictions\n",
    "        rfc = RandomForestClassifier(n_estimators=rf_est, max_features='sqrt') \n",
    "        rfc.fit(x_train,y_train)\n",
    "        predictions = rfc.predict(x_test)\n",
    "        \n",
    "        # create classification report, reformat column wise for each trial and append to a list\n",
    "        report = classification_report(y_test, predictions, output_dict=True)\n",
    "        class_rep_df = pd.DataFrame(report).reset_index().pivot(columns='index')\n",
    "        class_rep_df.columns = class_rep_df.columns.to_series().str.join('_') # flatten and concatenate multilevel column\n",
    "        class_rep_df.insert(0, 'GrpBy', '-')\n",
    "        class_rep_df = class_rep_df.groupby('GrpBy').sum().reset_index()\n",
    "        class_rep_df.drop('GrpBy',axis=1,inplace=True)\n",
    "        class_rep_df.drop(class_rep_df.iloc[:, 9:],axis=1,inplace=True)\n",
    "        class_rep_df.rename(columns={'accuracy_f1-score':'Accuracy'}, inplace=True)\n",
    "        class_rep_df.insert(9, 'Estimators', rf_est)\n",
    "        class_rep_df.insert(10, 'Trials', trials)\n",
    "        class_rep_df.insert(11, 'RandomState', i)\n",
    "              \n",
    "        # attach all data drames to a list \n",
    "        rf_models_list.append(class_rep_df)\n",
    "        \n",
    "    # convert list of dataframes to a single frame\n",
    "    rf_models_all_df = pd.concat(rf_models_list, ignore_index=True)\n",
    "    \n",
    "    # change order of columns\n",
    "    rf_models_all_df = rf_models_all_df[['0.0_precision', '0.0_recall', '0.0_f1-score', '0.0_support',  \n",
    "                                         '1.0_precision', '1.0_recall', '1.0_f1-score', '1.0_support', \n",
    "                                         'Accuracy', 'Estimators', 'Trials', 'RandomState']] \n",
    "    # rename columns\n",
    "    rf_models_all_df.rename(columns={ '0.0_precision':'0_precision', '0.0_recall':'0_recall', \n",
    "                                      '0.0_f1-score':'0_f1-score', '0.0_support':'0_support',\n",
    "                                      '1.0_precision':'1_precision', '1.0_recall':'1_recall', \n",
    "                                      '1.0_f1-score':'1_f1-score', '1.0_support':'1_support',}, inplace = True)\n",
    "\n",
    "    return rf_models_all_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Estimators</th>\n",
       "      <th>Trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_precision  0_recall  0_f1-score  0_support  1_precision  1_recall  \\\n",
       "0         0.83      0.88        0.86      165.0         0.79      0.71   \n",
       "\n",
       "   1_f1-score  1_support  Accuracy  Estimators  Trials  \n",
       "0        0.75      102.0      0.82        75.0    25.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display summarized results\n",
    "\n",
    "results_df = rf_mod_assess(modified_data_03_df, 'Survived', 25, 75)\n",
    "results_avg_df = pd.DataFrame(results_df.iloc[ 0:, results_df.columns != 'RandomState'  ].mean()).transpose()\n",
    "results_avg_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Estimators</th>\n",
       "      <th>RandomState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0_precision  0_recall  0_f1-score  0_support  1_precision  1_recall  \\\n",
       "0          0.88      0.91        0.89      185.0         0.78      0.72   \n",
       "12         0.84      0.89        0.86      175.0         0.76      0.68   \n",
       "24         0.77      0.89        0.82      157.0         0.79      0.63   \n",
       "\n",
       "    1_f1-score  1_support  Accuracy  Estimators  RandomState  \n",
       "0         0.75       82.0      0.85          75           21  \n",
       "12        0.72       92.0      0.82          75           19  \n",
       "24        0.70      110.0      0.78          75           22  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display top, middle, worst results, sort by Accuracy descending  \n",
    "results_df = rf_mod_assess(modified_data_03_df, 'Survived', 25, 75)\n",
    "results_df.sort_values(['Accuracy'], ascending=False, inplace=True)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df\n",
    "results_df.iloc[ [0, 12, 24], results_df.columns != 'Trials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Estimators</th>\n",
       "      <th>Trials</th>\n",
       "      <th>RandomState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.71</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0_precision  0_recall  0_f1-score  0_support  1_precision  1_recall  \\\n",
       "0          0.85      0.90        0.88      166.0         0.82      0.74   \n",
       "1          0.85      0.90        0.87      170.0         0.80      0.71   \n",
       "2          0.78      0.92        0.84      158.0         0.85      0.61   \n",
       "3          0.80      0.87        0.83      164.0         0.75      0.65   \n",
       "4          0.85      0.89        0.87      172.0         0.78      0.72   \n",
       "5          0.84      0.90        0.87      162.0         0.82      0.73   \n",
       "6          0.83      0.89        0.86      160.0         0.82      0.73   \n",
       "7          0.81      0.84        0.83      166.0         0.73      0.68   \n",
       "8          0.82      0.87        0.85      161.0         0.78      0.72   \n",
       "9          0.84      0.90        0.87      169.0         0.80      0.69   \n",
       "10         0.81      0.82        0.82      161.0         0.72      0.72   \n",
       "11         0.89      0.84        0.87      169.0         0.75      0.83   \n",
       "12         0.80      0.93        0.86      155.0         0.87      0.67   \n",
       "13         0.84      0.88        0.86      165.0         0.80      0.74   \n",
       "14         0.81      0.94        0.87      163.0         0.87      0.64   \n",
       "15         0.80      0.89        0.84      153.0         0.82      0.69   \n",
       "16         0.81      0.89        0.85      156.0         0.82      0.70   \n",
       "17         0.83      0.86        0.84      167.0         0.74      0.70   \n",
       "18         0.84      0.87        0.86      175.0         0.74      0.68   \n",
       "19         0.83      0.86        0.84      166.0         0.75      0.71   \n",
       "20         0.88      0.90        0.89      185.0         0.77      0.72   \n",
       "21         0.76      0.89        0.82      157.0         0.79      0.61   \n",
       "22         0.83      0.84        0.84      172.0         0.71      0.68   \n",
       "23         0.85      0.91        0.88      169.0         0.82      0.72   \n",
       "24         0.84      0.85        0.85      164.0         0.76      0.74   \n",
       "\n",
       "    1_f1-score  1_support  Accuracy  Estimators  Trials  RandomState  \n",
       "0         0.78      101.0      0.84          75      25            1  \n",
       "1         0.75       97.0      0.83          75      25            2  \n",
       "2         0.71      109.0      0.80          75      25            3  \n",
       "3         0.70      103.0      0.78          75      25            4  \n",
       "4         0.75       95.0      0.83          75      25            5  \n",
       "5         0.77      105.0      0.83          75      25            6  \n",
       "6         0.77      107.0      0.83          75      25            7  \n",
       "7         0.70      101.0      0.78          75      25            8  \n",
       "8         0.75      106.0      0.81          75      25            9  \n",
       "9         0.74       98.0      0.82          75      25           10  \n",
       "10        0.72      106.0      0.78          75      25           11  \n",
       "11        0.79       98.0      0.84          75      25           12  \n",
       "12        0.76      112.0      0.82          75      25           13  \n",
       "13        0.77      102.0      0.83          75      25           14  \n",
       "14        0.74      104.0      0.82          75      25           15  \n",
       "15        0.75      114.0      0.81          75      25           16  \n",
       "16        0.76      111.0      0.81          75      25           17  \n",
       "17        0.72      100.0      0.80          75      25           18  \n",
       "18        0.71       92.0      0.81          75      25           19  \n",
       "19        0.73      101.0      0.80          75      25           20  \n",
       "20        0.74       82.0      0.85          75      25           21  \n",
       "21        0.69      110.0      0.77          75      25           22  \n",
       "22        0.70       95.0      0.79          75      25           23  \n",
       "23        0.77       98.0      0.84          75      25           24  \n",
       "24        0.75      103.0      0.81          75      25           25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all results\n",
    "results_df = rf_mod_assess(modified_data_03_df, 'Survived', 25, 75)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02130164312911093"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispersion of accuracy \n",
    "\n",
    "np.std(results_df['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance\n",
    "\n",
    "# inputs\n",
    "dataframe = modified_data_03_df\n",
    "target = 'Survived'\n",
    "rnd_st = 19\n",
    "rf_est = 75\n",
    "# note: max features and scoring per sklearn documentation; otherwise parameters as per sklearn documentation\n",
    "\n",
    "# split data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataframe.drop(target,axis=1), \n",
    "                                                    dataframe[target], test_size=0.30, \n",
    "                                                    random_state=rnd_st)\n",
    "# make predictions\n",
    "rfc = RandomForestClassifier(n_estimators=rf_est, max_features='sqrt') \n",
    "rfc.fit(x_train,y_train)\n",
    "predictions = rfc.predict(x_test)\n",
    "\n",
    "# assess feature importance: Permutation Importances (Test Set)\n",
    "result = permutation_importance(rfc, x_test, y_test, n_repeats=10,\n",
    "                                random_state=rnd_st, n_jobs=2, scoring='accuracy')\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=x_test.columns[sorted_idx])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
